{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis in Python\n",
        "1. VADER (Valence Aware Dictionary and sEntiment Reasoner)-Bag of words approach\n",
        "\n",
        "2. Roberta pretrained Model from ðŸ¤—\n",
        "\n",
        "3. Huggingface Pipeline"
      ],
      "metadata": {
        "id": "lHlpeUZncFJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y7VuMGX_UALC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in data\n",
        "df = pd.read_csv('/content/drive/MyDrive/sentimentAnalysis/Reviews.csv')\n",
        "print(df.shape)\n",
        "df = df.head(500)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "9Awl0kQAWjXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Wav55By-W0Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick EDA\n"
      ],
      "metadata": {
        "id": "dEjKsl5WZIhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = df['Score'].value_counts().sort_index() \\\n",
        "    .plot(kind = 'bar',\n",
        "          title = 'Count of Reviews by Stars',\n",
        "          figsize = (10, 5))\n",
        "ax.set_xlabel('Review Stars')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "flgUfJ-aZMdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic NLTK"
      ],
      "metadata": {
        "id": "nfOPNtqcaImT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "KTEKN3RBaK-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = df['Text'][50]\n",
        "# print(example)"
      ],
      "metadata": {
        "id": "Tv68cQ15a31s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(example)\n",
        "tokens[:10]"
      ],
      "metadata": {
        "id": "tpsPuJgla9Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10]"
      ],
      "metadata": {
        "id": "NV8rBQ46bJQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities= nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ],
      "metadata": {
        "id": "oWP2d5zpbc5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VADER Sentiment Scoring\n",
        "\n",
        "We will use NLTK's SentimentIntensityAnalyzer to get the neg/neu/pos scores of the text.\n",
        "* This uses a \"bag of words\" approach:\n",
        "1. Stop words are removed\n",
        "2. Each word is scored and combined to a total score."
      ],
      "metadata": {
        "id": "rVRceTeqb7b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "KpfHNcGgcEB4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores('I am so happy!')"
      ],
      "metadata": {
        "id": "dnPu6Yp5y4XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores('This is the worst thing ever.')"
      ],
      "metadata": {
        "id": "gJ5BkRkAzHXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia.polarity_scores(example)"
      ],
      "metadata": {
        "id": "gezpaBybzN6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the polarity score on the entire dataset\n",
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total = len(df)):\n",
        "  text = row['Text']\n",
        "  myid = row['Id']\n",
        "  res[myid] = sia.polarity_scores(text)"
      ],
      "metadata": {
        "id": "bK59XraVzVJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vaders = pd.DataFrame(res).T\n",
        "vaders = vaders.reset_index().rename(columns = {'index' : 'Id'})\n",
        "vaders = vaders.merge(df, how = 'left')"
      ],
      "metadata": {
        "id": "jtWQQ1n12tqh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have sentiment score and metadata\n",
        "vaders.head()"
      ],
      "metadata": {
        "id": "gElyHEqQ3eAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot VADER results"
      ],
      "metadata": {
        "id": "gFGH_zNN3xQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.barplot(data = vaders, x = 'Score', y = 'compound')\n",
        "ax.set_title('Compound Score by Amazon Star Review')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tJA4qlJF3uga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize = (12, 3))\n",
        "sns.barplot(data = vaders, x = 'Score', y = 'pos', ax = axs[0])\n",
        "sns.barplot(data = vaders, x = 'Score', y = 'neu', ax = axs[1])\n",
        "sns.barplot(data = vaders, x = 'Score', y = 'neg', ax = axs[2])\n",
        "axs[0].set_title('Positive')\n",
        "axs[1].set_title('Neutral')\n",
        "axs[2].set_title('Negative')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lRbmlq6c48sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta Pretrained Model\n",
        "* Use a model trained of a large corpus of data.\n",
        "* Transformer model accounts for the words but also the context related to other words."
      ],
      "metadata": {
        "id": "J-8ygy6RIyNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kLIRwjgOJ_wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "cv1t-rSEJBI8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "vQc2yRQLJkaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VADER results on example\n",
        "print(example)\n",
        "sia.polarity_scores(example)"
      ],
      "metadata": {
        "id": "v_9CNV9ZKtLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run for Roberta Model\n",
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "output = model(**encoded_text)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "scores_dict = {\n",
        "    'roberta_neg' : scores[0],\n",
        "    'roberta_neu' : scores[1],\n",
        "    'roberta_pos' : scores[2]\n",
        "}\n",
        "print(scores_dict)"
      ],
      "metadata": {
        "id": "SaOOpODAK8fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity_scores_roberta(example):\n",
        "  encoded_text = tokenizer(example, return_tensors = 'pt')\n",
        "  output = model(**encoded_text)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "  scores_dict = {\n",
        "      'roberta_neg' : scores[0],\n",
        "      'roberta_neu' : scores[1],\n",
        "      'roberta_pos' : scores[2]\n",
        "  }\n",
        "  return scores_dict"
      ],
      "metadata": {
        "id": "kcYSqsmdMEoG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total = len(df)):\n",
        "  try:\n",
        "    text = row['Text']\n",
        "    myid = row['Id']\n",
        "    vader_result = sia.polarity_scores(text)\n",
        "    vader_result_rename = {}\n",
        "    for key, value in vader_result.items():\n",
        "      vader_result_rename[f\"vader_{key}\"] = value\n",
        "    roberta_result = polarity_scores_roberta(text)\n",
        "    both = {**vader_result_rename, **roberta_result}\n",
        "    res[myid] = both\n",
        "  except RuntimeError:\n",
        "    print(f'Broke for id {myid}')"
      ],
      "metadata": {
        "id": "8RZEU8vbMuzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(res).T\n",
        "results_df = results_df.reset_index().rename(columns = {'index' : 'Id'})\n",
        "results_df = results_df.merge(df, how = 'left')"
      ],
      "metadata": {
        "id": "mQcXGq2RM7-3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Scores between models"
      ],
      "metadata": {
        "id": "ShGFG9PTQbwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.columns"
      ],
      "metadata": {
        "id": "s8N5QTdJSYQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = results_df,\n",
        "             vars = ['vader_neg', 'vader_neu', 'vader_pos',\n",
        "                     'roberta_neg','roberta_neu', 'roberta_pos'],\n",
        "            hue = 'Score',\n",
        "            palette = 'tab10')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rGVvovj4Qebb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reviewing Examples:\n",
        "* Positive 1-Star and Negative 5-Star Reviews\n",
        "\n",
        "Lets look at some examples where the model scoring and review score differ the most."
      ],
      "metadata": {
        "id": "I7D2uNyFUDVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive Sentiment 1-Star review\n",
        "results_df.query('Score == 1') \\\n",
        "  .sort_values('roberta_pos', ascending=False)['Text'].values[0]"
      ],
      "metadata": {
        "id": "bXVPRkPeUTlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.query('Score == 1') \\\n",
        "  .sort_values('vader_pos', ascending=False)['Text'].values[0]"
      ],
      "metadata": {
        "id": "8jb8NvhKU6PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative Sentiment 5-Star review\n",
        "results_df.query('Score == 5') \\\n",
        "  .sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ],
      "metadata": {
        "id": "Q7rAxjILVJiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.query('Score == 5') \\\n",
        "  .sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ],
      "metadata": {
        "id": "YvM_ItyuVOWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End"
      ],
      "metadata": {
        "id": "4drL9g0JWJJY"
      }
    }
  ]
}